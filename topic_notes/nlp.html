<!DOCTYPE html>
<html>
  <head>
    <link rel="stylesheet" href="/mysite.css">
  </head>
  <body>
    <!-- Menu Bar -->
    <div class="topnav">
      <a href="/index.html">Home</a>
      <a href="/projects.html">Projects</a>
      <a href="/resources.html">Resources</a>
      <a class="active" href="/topics.html">Topics</a>
      <a href="/talks.html">Talks</a>
      <a href="/about.html">About</a>
    </div>
    
    <h1>Natural Language Processing</h1>
    <center>Some notes and useful resources on NLP. </center>

    <br><br>

    <h3>Resources</h3>

    <b>Books</b>

    <li><a href="https://mitpress.mit.edu/books/foundations-statistical-natural-language-processing">Foundations of Statistical Natural Language Processing (Manning and Schutze)</a></li>

    <li><a href="http://shop.oreilly.com/product/0636920052555.do">Applied Text Analysis with Python (Bengfort, Bilbro and Ojeda)</a></li>

    <li><a href="https://www.morganclaypool.com/doi/abs/10.2200/S00809ED2V01Y201710HLT038">Natural Language Processing for Social Media (Farzinder and Inkpen)</a></li>

    <br><br>

    <b>Code Examples</b>

    <li><a href="https://www.kaggle.com/learn/natural-language-processing">Natural Language Processing (Kaggle)</a></li>

    <li><a href="https://www.dataquest.io/blog/natural-language-processing-with-python/">Natural Language Processing with Python</a></li>

    <li><a href="https://medium.com/@b.terryjack/nlp-pre-trained-sentiment-analysis-1eb52a9d742c">NLP: Pre-trained Sentiment Analysis</a></li>

    <li><a href="https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/">Text Classification in Python Using Spacy</a></li>

    <li><a href="https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/">A Visual Guide to Using BERT for the First Time</a></li>

    <li><a href="https://towardsml.com/2019/09/17/bert-explained-a-complete-guide-with-theory-and-tutorial/">BERT Explained: A Complete Guide with Theory and Tutorial</a></li>

    <li><a href="https://explosion.ai/blog/spacy-transformers?ref=Welcome.AI">spaCy meets Transformers: Fine-tune BERT, XLNet and GPT-2</a></li>

    <li><a href="https://colab.research.google.com/drive/18SVeIFXWCiA9HL4WVCAFxlfH59ez6atc">Sentiment Analysis of IMDb Movie Reviews Using BERT</a> (from <a href="https://towardsdatascience.com/bert-text-classification-in-3-lines-of-code-using-keras-264db7e7a358">this article</a>)</li>

    <li><a href="https://huggingface.co/blog/how-to-train">How to train a new language model from scratch using Transformers and Tokenizers</a></li>

    <br><br>

    <b>Courses</b>

    <li><a href="https://www.kaggle.com/learn/natural-language-processing">Natural Language Processing (Kaggle)</a></li>

    <li><a href="https://www.coursera.org/learn/natural-language-processing-tensorflow">Natural Language Processing in Tensorflow (Coursera)</a></li>

    <li><a href="https://www.coursera.org/learn/nlp-sequence-models">Sequence Models (Coursera)</a></li>

    <li><a href="https://github.com/ines/spacy-course"> SpaCy (Ines Montani) </a></li>

    <li><a href="https://github.com/oreillymedia/Learning-Path-Mastering-SpaCy-for-Natural-Language-Processing">Mastering SpaCy for Natural Language Processing Examples</a></li>


    <br><br>

    <b>Papers</b>
    
    
    <li><a href="https://www.researchgate.net/publication/13853244_Long_Short-term_Memory">Long Short-term Memory (1997, Hochreiter and Schmidhuber)</a></li>
    
    <li><a href="https://papers.nips.cc/paper/1839-a-neural-probabilistic-language-model.pdf">A Neural Probabilistic Language Model (2003, Bengio et al)</a></li>

    <li><a href="https://arxiv.org/pdf/1412.3555v1.pdf">Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling (2014, Chung et al)</a></li>
    
    <li><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate (2014, Bahdanau et al)</a></li>
    
    <li><a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need (2017, Vaswani et al)</a></li>
    
    <li><a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (2018, Devlin et al)</a></li>
    
    <li><a href="https://arxiv.org/abs/1904.09077">Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT (2019, Wu and Dredze)</a></li>

    <li><a href="http://personales.upv.es/prosso/resources/BasileEtAl_SemEval19.pdf">SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter (2019, Basile et al)</a></li>
    
    <li><a href="https://arxiv.org/abs/2002.12327">A Primer in BERTology: What we know about how BERT works (2020, Rogers et al)</a></li>

    <br><br>

    
    <b>Short Tutorials and Other Articles</b>

    <li><a href="https://jalammar.github.io/illustrated-bert/">The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)</a></li>

    <li><a href="https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469">Understanding Word Vectors (Allison Parrish)</a></li>

    <li><a href="https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#32-understanding-the-output">BERT Word Embeddings Tutorial (May 2019)</a></li>

    <li><a href="http://mccormickml.com/2019/11/11/bert-research-ep-1-key-concepts-and-sources/">BERT Research - Ep. 1 - Key Concepts & Sources (Nov 2019)</a></li>

    <li><a href="https://ruder.io/state-of-transfer-learning-in-nlp/">The State of Transfer Learning in NLP (Aug 2019)</a></li>

    <li><a href="https://ruder.io/research-highlights-2019/index.html">10 ML & NLP Research Highlights of 2019</a></li>



    <br><br>

    <b>Videos/Presentations</b>

    <li><a href="https://www.youtube.com/watch?v=WHocRqT-KkU"> Kevin Markham's PyCon2016 Tutorial: Machine Learning with Text in scikit-learn </a></li> 
    
    <li><a href="https://youtu.be/6zm9NC9uRkk">Modern NLP in Python (PyData DC 2016)</a></li>

    <li><a href="https://www.youtube.com/playlist?list=PLam9sigHPGwOBuH4_4fr-XvDbe5uneaf6">BERT Research Explained (Chris McCormicAI)</a></li>


    <img src="BERT_Mountain.png" width=300><br>
    BERT Mountain" illustration from <br>

    <a href="https://www.youtube.com/watch?v=FKlPCK1uFrc&list=PLam9sigHPGwOBuH4_4fr-XvDbe5uneaf6&index=2&t=0s">"Chris McCormickAI on YouTube</a>

    <br><br>

    <h3>Use Cases</h3>

    <li>Text classification e.g. sentiment analysis</li>
    <li>Search</li>
    <li>Recommendations</li>
    <li>Question answering</li>

    <h3>Sub-Topics</h3>

    <ul>
      <li>Text Normalisation: e.g. stemming, lemmatisation</li>
      <li>Shape Analysis</li>
      <li>Tokenisation: e.g. bag of words, n-grams</li>
      <li>Token-level Entity Analysis</li>
      <li>Token Attribute Analysis</li>
      <li>Token Count, Term Frequency-Inverse Document Frequency (TF-IDF)</li>
      <li>Dealing with Stop Words (Generic & Corpus Specific), Punctuation, Case, Incorrect Spelling, Emojis</li>
      <li>Word Vector Embedding, Word2Vec, GLoVE</li>
      <li>Word Vector Visualisation with t-SNE</li>
      <li>Sentence Detection</li>
      <li>Named Entity Recognition</li>
      <li>Part Of Speech (POS) Tagging</li>
      <li>Phrase Modelling</li>
      <li>Topic Modelling and LDA (Latent Dirichlet Allocation)</li>
      <li>Tools: Spacy, Gensim, Scikit-Learn, NLTK, BERT</li>
    </ul>



    <br><br>
    
  </body>
</html>